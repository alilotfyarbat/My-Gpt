# My-Gpt
هوش مصنوعی محلی با استفاده از Ollama و رابط کاربری (UI)
**نام پروژه: LocalAI-WebUI**

---

### **توضیحات پروژه**
این پروژه یک رابط کاربری تحت وب ساده و کاربرپسند برای مدیریت و تعامل با مدل‌های هوش مصنوعی محلی ارائه می‌دهد. با استفاده از Ollama ، کاربران می‌توانند مدل‌های زبانی بزرگ (LLMs) را به صورت محلی نصب کنند و بدون نیاز به اتصال به اینترنت یا استفاده از APIهای خارجی، مستقیماً با آن‌ها تعامل داشته باشند. این ابزار برای توسعه‌دهندگان، محققان و علاقه‌مندان به هوش مصنوعی طراحی شده است تا بتوانند به راحتی از قابلیت‌های مدل‌های هوش مصنوعی در محیط محلی استفاده کنند.

با استفاده از LocalAI-WebUI ، کاربران می‌توانند از طریق یک رابط گرافیکی تمیز و واکنش‌گرا با مدل‌های زبانی تعامل کنند. این پروژه از زبان‌های مختلف پشتیبانی می‌کند و به ویژه برای کاربران فارسی‌زبان، قابلیت نمایش صحیح متون فارسی (RTL) و انگلیسی (LTR) را فراهم می‌کند. همچنین، امکان مقایسه خروجی‌های چندین مدل به صورت همزمان وجود دارد که آن را به ابزاری ایده‌آل برای تست و تحقیق تبدیل می‌کند.
### **ویژگی‌های کلیدی**
1. **مدیریت مدل‌های محلی با Ollama**:
   - نصب و مدیریت آسان مدل‌های مختلف هوش مصنوعی.
   - حفظ حریم خصوصی: تمامی داده‌ها به صورت محلی پردازش می‌شوند و نیازی به ارسال اطلاعات به سرورهای خارجی نیست.

2. **رابط کاربری (UI)**:
   - رابط وب تمیز، واکنش‌گرا و کاربرپسند.
   - پشتیبانی از زبان‌های مختلف، از جمله فارسی و انگلیسی.
   - نمایش صحیح متون فارسی (RTL) و انگلیسی (LTR).
   - حالت تیره (Dark Mode) برای تجربه کاربری بهتر.

3. **مقایسه مدل‌ها**:
   - امکان مقایسه خروجی‌های چندین مدل به صورت همزمان.
   - ارزیابی عملکرد مدل‌ها برای وظایف مختلف مانند ترجمه، خلاصه‌سازی و تولید متن.

4. **پاسخ‌های استریم بلادرنگ**:
   - دریافت پاسخ‌ها به صورت بلادرنگ و استریم شده.

5. **مدیریت خطا و بازیابی**:
   - مدیریت جامع خطاها، شامل مشکلات اتصال، انتخاب مدل‌های نامعتبر، سناریوهای Timeout و خطاهای عمومی API.

6. **تاریخچه جستجو**:
   - ذخیره و بازیابی تاریخچه پرسش‌ها و پاسخ‌ها.

7. **قابلیت سفارشی‌سازی**:
   - شخصی‌سازی رابط کاربری برای نیازهای خاص کاربران.
   - اضافه کردن ویژگی‌های جدید مانند تحلیل عملکرد مدل‌ها یا ابزارهای تجسم داده.

8. **طراحی سازگار با دسکتاپ**:
   - رابط کاربری بهینه‌شده برای استفاده در دستگاه‌های دسکتاپ.

---

### **موارد استفاده**
- **تحقیق و توسعه**: تست و ارزیابی مدل‌های مختلف برای اهداف تحقیقاتی.
- **پروژه‌های چندزبانه**: استفاده از مدل‌ها برای پردازش متون فارسی و انگلیسی.
- **آموزش**: آموزش دانشجویان درباره مدل‌های هوش مصنوعی و کاربردهای آن‌ها.
- **توسعه نرم‌افزار**: استفاده از مدل‌های محلی برای توسعه برنامه‌های هوش مصنوعی بدون نیاز به اتصال به سرورهای خارجی.
- **تولید محتوا**: تولید محتوای باکیفیت در چندین زبان برای وبلاگ‌ها، مقالات یا شبکه‌های اجتماعی.

---

### **پیش‌نیازها**
برای نصب و استفاده از LocalAI-WebUI، به موارد زیر نیاز دارید:
1. **Python نسخه ۳.۸ یا بالاتر** ([دانلود](https://www.python.org/downloads/)).
2. **Visual Studio Code** ([دانلود](https://code.visualstudio.com/Download)).
3. **Ollama** (آخرین ورژن) ([دانلود](https://ollama.com/download)).
4. **مدل‌های مورد نیاز در Ollama**:
   - `qwen2.5:1.5b`
   - `deepseek-r2:1.5b`

---

### **مراحل نصب و راه‌اندازی**
1. **نصب Ollama**:
   - از آدرس [https://ollama.com/download](https://ollama.com/download)، نسخه سازگار با سیستم عامل خود را دانلود و نصب کنید.

2. **نصب Python**:
   - آخرین نسخه Python را از [https://www.python.org/downloads/](https://www.python.org/downloads/) دانلود و نصب کنید.

3. **نصب Visual Studio Code**:
   - ویرایشگر کد VS Code را از [https://code.visualstudio.com/Download](https://code.visualstudio.com/Download) دانلود و نصب کنید.

4. **انتخاب و نصب مدل‌ها**:
   - به سایت Ollama بروید و از قسمت [https://ollama.com/models](https://ollama.com/models)، مدل‌های مورد نظر خود را انتخاب و نصب کنید.

5. **اجرای پروژه**:
   - فایل زیپ پروژه را از حالت فشرده خارج کنید.
   - پوشه پروژه را به صورت کامل در Visual Studio Code باز کنید.
   - فایل `app.py` را اجرا کنید.

6. **استفاده از رابط کاربری**:
   - در فیلد مربوطه، پرامپت خود را وارد کنید.
   - مدل‌های مورد نظر را از لیست انتخاب کنید.
   - دکمه Enter را فشار دهید و منتظر پاسخ باشید.

---

### **مدیریت خطاها**
این برنامه شامل مدیریت جامع خطا برای موارد زیر است:
- مشکلات اتصال به Ollama.
- انتخاب مدل‌های نامعتبر.
- سناریوهای Timeout.
- خطاهای عمومی API.
- خطاهای اتصال.

---

### **جمع‌بندی**
LocalAI-WebUI یک ابزار قدرتمند و کاربرپسند است که به کاربران امکان تعامل با مدل‌های هوش مصنوعی محلی را می‌دهد. با استفاده از این پروژه، کاربران می‌توانند به راحتی مدل‌های مختلف را مدیریت، مقایسه و از آن‌ها در پروژه‌های خود استفاده کنند. این پروژه به ویژه برای کاربران فارسی‌زبان و پروژه‌های چندزبانه مناسب است و از ویژگی‌هایی مانند پاسخ‌های استریم بلادرنگ، حالت تیره و تاریخچه جستجو پشتیبانی می‌کند.

**تبریک! شما موفق شدید.**
